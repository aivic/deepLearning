{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Fashion MNIST to describe the use of following optimizers -\n",
    "* SGD\n",
    "* Adam\n",
    "* Adagrad\n",
    "* Adadelta\n",
    "* RMSProp\n",
    "* NAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras # Don't import keras from tensorflow like (from tensorflow import keras)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading train and test data\n",
    "train_data = pd.read_csv('fashion-mnist_train.csv')\n",
    "test_data = pd.read_csv('fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making validation data out of test data\n",
    "val_data = test_data.iloc[:5000,:]\n",
    "test_data = test_data.iloc[5000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the labels\n",
    "train_labels = train_data.label\n",
    "val_labels = val_data.label\n",
    "test_labels = test_data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping training data\n",
    "train_images = train_data.iloc[:,1:].values.reshape(60000, 28, 28)\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping validation data\n",
    "val_images = val_data.iloc[:,1:].values.reshape(5000, 28, 28)\n",
    "val_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping test data\n",
    "test_images = test_data.iloc[:,1:].values.reshape(5000, 28, 28)\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data in the range of 0-1\n",
    "train_images = train_images/255.0\n",
    "val_images = val_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining multi-layer perceptron model with 1 hidden layer having 256 neurons and output layer with 10 possible answers\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), # Perform conversion of higher dimensional data (here, 2-D) to 1-D data.\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu), # Hidden layer with 256 neurons and ReLU activation function\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax) # Output layer with softmax activation function \n",
    "])                                                   # which gives final output in terms of probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def models_with_different_optimizers(list_of_optimizers):    \n",
    "    \n",
    "    for i in range(len(list_of_optimizers)):        \n",
    "        model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=list_of_optimizers[i], # Learning rate and momentum can be passed inside optimizer\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "        # Traning the model and writing log files for TensorBoard in distinct directories        \n",
    "        val = re.search('optimizers\\..*\\so', str(list_of_optimizers[i])).group(0)[11:][:-2] # Fetching optimizer name\n",
    "        logdir = r'optims\\\\' + val # Each log file needs to be written in a distinct directory. (Mandatory)\n",
    "        \n",
    "        # Writing graph will take time. Hence, keeping it False.\n",
    "        cb = keras.callbacks.TensorBoard(log_dir=logdir, write_graph=False) \n",
    "        epochs = 5\n",
    "        print('Building model using '+ val + ' optimizer')\n",
    "        history = model.fit(train_images, train_labels, epochs=epochs, \n",
    "                           validation_data=(val_images, val_labels),\n",
    "                           callbacks=[cb])\n",
    "        print('Model built sucessfully.')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model using Adam optimizer\n",
      "Train on 60000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.2835 - acc: 0.8981 - val_loss: 0.3651 - val_acc: 0.8754\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.2540 - acc: 0.9072 - val_loss: 0.2941 - val_acc: 0.8908\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.2372 - acc: 0.9117 - val_loss: 0.3281 - val_acc: 0.8846\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.2263 - acc: 0.9151 - val_loss: 0.3072 - val_acc: 0.8910\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.2168 - acc: 0.9193 - val_loss: 0.3289 - val_acc: 0.8832\n",
      "Model built sucessfully.\n",
      "\n",
      "Building model using Adadelta optimizer\n",
      "Train on 60000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.1996 - acc: 0.9264 - val_loss: 0.3235 - val_acc: 0.8938\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.2018 - acc: 0.9257 - val_loss: 0.3080 - val_acc: 0.9022\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.2102 - acc: 0.9246 - val_loss: 0.3955 - val_acc: 0.8744\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.2200 - acc: 0.9225 - val_loss: 0.3977 - val_acc: 0.8778\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 0.2383 - acc: 0.9186 - val_loss: 0.3692 - val_acc: 0.8912\n",
      "Model built sucessfully.\n",
      "\n",
      "Building model using Adagrad optimizer\n",
      "Train on 60000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.2197 - acc: 0.9286 - val_loss: 0.3280 - val_acc: 0.8952\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.1527 - acc: 0.9433 - val_loss: 0.3129 - val_acc: 0.8992\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.1442 - acc: 0.9469 - val_loss: 0.3042 - val_acc: 0.9002\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.1391 - acc: 0.9486 - val_loss: 0.3067 - val_acc: 0.8992\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.1348 - acc: 0.9501 - val_loss: 0.3032 - val_acc: 0.9032\n",
      "Model built sucessfully.\n",
      "\n",
      "Building model using RMSprop optimizer\n",
      "Train on 60000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.2438 - acc: 0.9183 - val_loss: 0.3921 - val_acc: 0.8870\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.2157 - acc: 0.9254 - val_loss: 0.4188 - val_acc: 0.8810\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.2010 - acc: 0.9306 - val_loss: 0.3986 - val_acc: 0.8900\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.1972 - acc: 0.9318 - val_loss: 0.3730 - val_acc: 0.8918\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.1943 - acc: 0.9322 - val_loss: 0.4644 - val_acc: 0.8866\n",
      "Model built sucessfully.\n",
      "\n",
      "Building model using SGD optimizer\n",
      "Train on 60000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.1387 - acc: 0.9508 - val_loss: 0.3380 - val_acc: 0.9046\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.1248 - acc: 0.9549 - val_loss: 0.3374 - val_acc: 0.9020\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.1212 - acc: 0.9565 - val_loss: 0.3326 - val_acc: 0.9044\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1185 - acc: 0.9574 - val_loss: 0.3334 - val_acc: 0.9044\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.1168 - acc: 0.9574 - val_loss: 0.3324 - val_acc: 0.9050\n",
      "Model built sucessfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optims = [keras.optimizers.Adam(), keras.optimizers.Adadelta(), \n",
    "          keras.optimizers.Adagrad(), keras.optimizers.RMSprop(), \n",
    "          keras.optimizers.SGD()]\n",
    "models_with_different_optimizers(optims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run following command in Anaconda prompt after changing directory to the place which holds `optims`\n",
    "tensorboard --logdir=optims  \n",
    "Use .* under tensorboard to visualize all 4 graphs in first section.  \n",
    "You can also change `Horizontal Axis` from `Step` to `Relative` which describes relative time taken by each algorithm to finish."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

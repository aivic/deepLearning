{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing regularization on Fashion MNIST dataset using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras # Don't import keras from tensorflow like (from tensorflow import keras)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading train and test data\n",
    "train_data = pd.read_csv('fashion-mnist_train.csv')\n",
    "test_data = pd.read_csv('fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Making validation data out of test data\n",
    "val_data = test_data.iloc[:5000,:]\n",
    "test_data = test_data.iloc[5000:,:]\n",
    "\n",
    "# Fetching the labels\n",
    "train_labels = train_data.label\n",
    "val_labels = val_data.label\n",
    "test_labels = test_data.label\n",
    "\n",
    "# Reshaping training data\n",
    "train_images = train_data.iloc[:,1:].values.reshape(60000, 28, 28)\n",
    "\n",
    "# Reshaping validation data\n",
    "val_images = val_data.iloc[:,1:].values.reshape(5000, 28, 28)\n",
    "\n",
    "# Reshaping test data\n",
    "test_images = test_data.iloc[:,1:].values.reshape(5000, 28, 28)\n",
    "\n",
    "# Scaling data in the range of 0-1\n",
    "train_images = train_images/255.0\n",
    "val_images = val_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularization(list_of_regs, reg_names):\n",
    "    for reg_init in range(len(list_of_regs)):        \n",
    "        # Writing structure of model\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(28, 28)), \n",
    "            keras.layers.Dense(256, kernel_regularizer=list_of_regs[reg_init], activation=tf.nn.relu), \n",
    "            keras.layers.Dense(10, activation=tf.nn.softmax) \n",
    "        ])      \n",
    "\n",
    "        # Defining parameters like optmizer, loss function and evaluating metric\n",
    "        model.compile(loss='sparse_categorical_crossentropy', # \n",
    "                      optimizer=keras.optimizers.Adam(), # Learning rate and momentum can be passed inside optimizer\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # Traning the model and writing log file for TensorBoard\n",
    "        \n",
    "        logdir = r'regularization\\\\' + reg_names[reg_init] # Each log file needs to be written in a distinct directory. (Mandatory)        \n",
    "\n",
    "        # To store tensorboard graph logs\n",
    "        cb_tensorboard = keras.callbacks.TensorBoard(log_dir=logdir, write_graph=False) \n",
    "\n",
    "        epochs = 5\n",
    "        print('Model building using ' + reg_names[reg_init] + ' Regularization')\n",
    "        model.fit(train_images, train_labels, epochs=epochs, \n",
    "                    validation_data=(val_images, val_labels),\n",
    "                    callbacks=[cb_tensorboard])\n",
    "        print('Model built successfully.')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model building using Ridge.L2 Regularization\n",
      "Train on 60000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.9248 - acc: 0.7883 - val_loss: 0.6838 - val_acc: 0.8050\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.6766 - acc: 0.8036 - val_loss: 0.6855 - val_acc: 0.8118\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.6445 - acc: 0.8134 - val_loss: 0.5912 - val_acc: 0.8368\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.6159 - acc: 0.8196 - val_loss: 0.5884 - val_acc: 0.8380\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.6005 - acc: 0.8238 - val_loss: 0.5984 - val_acc: 0.8282\n",
      "Model built successfully.\n",
      "\n",
      "Model building using Lasso.L1 Regularization\n",
      "Train on 60000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 2.8723 - acc: 0.7009 - val_loss: 1.4166 - val_acc: 0.7372\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 1.3397 - acc: 0.7508 - val_loss: 1.2983 - val_acc: 0.7574\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 1.2719 - acc: 0.7605 - val_loss: 1.2773 - val_acc: 0.7598\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 1.2401 - acc: 0.7653 - val_loss: 1.2366 - val_acc: 0.7524\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 1.2151 - acc: 0.7700 - val_loss: 1.2330 - val_acc: 0.7578\n",
      "Model built successfully.\n",
      "\n",
      "Model building using Elastic.Net.L1.L2 Regularization\n",
      "Train on 60000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 2.9372 - acc: 0.6938 - val_loss: 1.5532 - val_acc: 0.7070\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 1.3868 - acc: 0.7366 - val_loss: 1.3031 - val_acc: 0.7548\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 15s 242us/step - loss: 1.3095 - acc: 0.7496 - val_loss: 1.2559 - val_acc: 0.7572\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 1.2628 - acc: 0.7599 - val_loss: 1.2538 - val_acc: 0.7606\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 1.2341 - acc: 0.7661 - val_loss: 1.2344 - val_acc: 0.7708\n",
      "Model built successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Value of lambda can be calculated using cross-validation\n",
    "list_of_regs = [keras.regularizers.l2(), keras.regularizers.l1(), keras.regularizers.l1_l2()] \n",
    "reg_names = ['Ridge.L2', 'Lasso.L1', 'Elastic.Net.L1.L2']\n",
    "regularization(list_of_regs, reg_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open tensorboard in `regularization` directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
